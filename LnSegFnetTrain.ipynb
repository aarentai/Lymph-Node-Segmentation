{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from dataset import *\n",
    "from model import *\n",
    "from loss import *\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode='gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode=='gpu':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # after switch device, you need restart the kernel\n",
    "#     torch.cuda.set_device(1)\n",
    "    torch.set_default_tensor_type('torch.cuda.DoubleTensor')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For classifications(segmentation=voxel-wise classification), `F.softmax(output, dim=1)` is very necessary at the end of the model, as it constraints the output into a probability, or you may have negative value that you also have no clue where it comes from.\n",
    "2. The numerator in dice loss for each category is very much like the cross entropy: a softmax vector inner product with a one-hot vector - only the value at where one is matters.\n",
    "2. For segmentation, use dice loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume:True, save_model:True\n"
     ]
    }
   ],
   "source": [
    "resume = True\n",
    "save_model = True\n",
    "print(f'resume:{resume}, save_model:{save_model}')\n",
    "output_dir = 'Models/Fnet'\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params 176982, # conv layers 40\n",
      "Starting from iteration 7 to iteration 108\n"
     ]
    }
   ],
   "source": [
    "epoch_loss_list = []\n",
    "epoch_num = 101\n",
    "start_epoch_num = 7\n",
    "batch_size = 12\n",
    "learning_rate = 5e0\n",
    "\n",
    "model = FNet()\n",
    "model.train()\n",
    "if mode=='gpu':\n",
    "    model.cuda()\n",
    "net = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "\n",
    "dataset = FnetDataset(root_dir='/home/sci/hdai/Projects/Dataset/LymphNodes')\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "if resume:\n",
    "    checkpoint = torch.load(f'{output_dir}/epoch_{start_epoch_num-1}_checkpoint.pth.tar')    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    with open(f'{output_dir}/loss.txt', 'a') as f:\n",
    "        f.write(f'From {start_epoch_num} to {epoch_num+start_epoch_num}\\n')\n",
    "        f.write(f'Dice; Adadelta, lr={learning_rate}; batch size: {batch_size}\\n')\n",
    "else:\n",
    "    start_epoch_num = 0  \n",
    "    \n",
    "    with open(f'{output_dir}/loss.txt', 'w+') as f:\n",
    "        f.write(f'From {start_epoch_num} to {epoch_num+start_epoch_num}\\n')\n",
    "        f.write(f'Dice; Adadelta: lr={learning_rate}; batch size: {batch_size}\\n')\n",
    "    \n",
    "print(f'Starting from iteration {start_epoch_num} to iteration {epoch_num+start_epoch_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/101 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [02:53, 173.77s/it]\u001b[A\n",
      "2it [05:32, 164.99s/it]\u001b[A\n",
      "3it [08:05, 159.62s/it]\u001b[A\n",
      "4it [10:42, 158.58s/it]\u001b[A\n",
      "5it [13:18, 157.45s/it]\u001b[A\n",
      "6it [15:46, 154.47s/it]\u001b[A\n",
      "7it [18:18, 153.61s/it]\u001b[A\n",
      "8it [19:27, 145.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 innerdomain loss: 4.076993491798993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/101 [19:28<32:27:27, 1168.47s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:53, 113.03s/it]\u001b[A\n",
      "2it [03:39, 108.96s/it]\u001b[A\n",
      "3it [05:32, 111.14s/it]\u001b[A\n",
      "4it [07:25, 111.75s/it]\u001b[A\n",
      "5it [09:21, 113.38s/it]\u001b[A\n",
      "6it [11:10, 111.79s/it]\u001b[A\n",
      "7it [13:14, 115.65s/it]\u001b[A\n",
      "8it [14:04, 105.56s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 innerdomain loss: 4.079719769197151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/101 [33:33<26:54:23, 978.42s/it] \n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:44, 104.96s/it]\u001b[A\n",
      "2it [03:28, 104.15s/it]\u001b[A\n",
      "3it [05:18, 106.86s/it]\u001b[A\n",
      "4it [06:57, 103.81s/it]\u001b[A\n",
      "5it [08:43, 104.56s/it]\u001b[A\n",
      "6it [10:24, 103.39s/it]\u001b[A\n",
      "7it [12:10, 104.04s/it]\u001b[A\n",
      "8it [12:51, 96.43s/it] \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 innerdomain loss: 4.0776736564132205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/101 [46:26<24:04:29, 884.38s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:47, 107.10s/it]\u001b[A\n",
      "2it [03:38, 109.86s/it]\u001b[A\n",
      "3it [05:22, 106.98s/it]\u001b[A\n",
      "4it [07:08, 106.47s/it]\u001b[A\n",
      "5it [08:56, 107.15s/it]\u001b[A\n",
      "6it [10:32, 103.35s/it]\u001b[A\n",
      "7it [12:13, 102.54s/it]\u001b[A\n",
      "8it [12:52, 96.55s/it] \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 innerdomain loss: 4.075621725251256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/101 [59:19<22:38:57, 840.59s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:44, 104.09s/it]\u001b[A\n",
      "2it [03:29, 104.74s/it]\u001b[A\n",
      "3it [05:17, 106.43s/it]\u001b[A\n",
      "4it [06:56, 103.24s/it]\u001b[A\n",
      "5it [08:41, 103.91s/it]\u001b[A\n",
      "6it [10:28, 104.92s/it]\u001b[A\n",
      "7it [12:09, 103.73s/it]\u001b[A\n",
      "8it [12:51, 96.38s/it] \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 innerdomain loss: 4.079436348448593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 5/101 [1:12:12<21:45:33, 815.97s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:43, 103.19s/it]\u001b[A\n",
      "2it [03:28, 104.68s/it]\u001b[A\n",
      "3it [05:13, 104.40s/it]\u001b[A\n",
      "4it [06:56, 103.97s/it]\u001b[A\n",
      "5it [08:42, 104.74s/it]\u001b[A\n",
      "6it [10:24, 103.82s/it]\u001b[A\n",
      "7it [12:10, 104.64s/it]\u001b[A\n",
      "8it [12:47, 95.96s/it] \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 innerdomain loss: 4.076389387851168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/101 [1:25:01<21:06:40, 800.01s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:47, 107.17s/it]\u001b[A\n",
      "2it [03:29, 104.43s/it]\u001b[A\n",
      "3it [05:14, 104.52s/it]\u001b[A\n",
      "4it [06:57, 103.80s/it]\u001b[A\n",
      "5it [08:40, 103.82s/it]\u001b[A\n",
      "6it [10:19, 102.14s/it]\u001b[A\n",
      "7it [11:59, 101.19s/it]\u001b[A\n",
      "8it [12:39, 94.90s/it] \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 innerdomain loss: 4.082530263907854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/101 [1:37:41<20:32:48, 786.90s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:35, 95.03s/it]\u001b[A\n",
      "2it [03:18, 100.10s/it]\u001b[A\n",
      "3it [04:51, 96.92s/it] \u001b[A\n",
      "4it [06:19, 93.39s/it]\u001b[A\n",
      "5it [08:06, 98.31s/it]\u001b[A\n",
      "6it [09:48, 99.50s/it]\u001b[A\n",
      "7it [11:27, 99.37s/it]\u001b[A\n",
      "8it [12:05, 90.70s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 innerdomain loss: 4.0868927567141204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/101 [1:49:47<19:49:49, 767.63s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:38, 98.27s/it]\u001b[A\n",
      "2it [03:18, 99.15s/it]\u001b[A\n",
      "3it [05:01, 101.15s/it]\u001b[A\n",
      "4it [06:43, 101.49s/it]\u001b[A\n",
      "5it [08:23, 100.80s/it]\u001b[A\n",
      "6it [10:03, 100.71s/it]\u001b[A\n",
      "7it [11:41, 99.89s/it] \u001b[A\n",
      "8it [12:17, 92.18s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 innerdomain loss: 4.076055617858074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/101 [2:02:06<19:23:10, 758.59s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:39, 99.96s/it]\u001b[A\n",
      "2it [03:18, 99.36s/it]\u001b[A\n",
      "3it [04:56, 98.42s/it]\u001b[A\n",
      "4it [06:36, 99.23s/it]\u001b[A\n",
      "5it [08:19, 100.70s/it]\u001b[A\n",
      "6it [10:03, 101.55s/it]\u001b[A\n",
      "7it [11:37, 99.09s/it] \u001b[A\n",
      "8it [12:15, 91.93s/it]\u001b[A\n",
      " 10%|▉         | 10/101 [2:14:22<18:59:56, 751.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 innerdomain loss: 4.08032973451937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:39, 99.80s/it]\u001b[A\n",
      "2it [03:21, 100.92s/it]\u001b[A\n",
      "3it [06:30, 130.14s/it]\u001b[A\n",
      " 10%|▉         | 10/101 [2:20:52<21:22:00, 845.28s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.00 GiB (GPU 0; 23.65 GiB total capacity; 14.76 GiB already allocated; 844.94 MiB free; 20.54 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-248adfcb484d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         loss = criterion(output_pred, output_true.squeeze())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch17/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch17/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.00 GiB (GPU 0; 23.65 GiB total capacity; 14.76 GiB already allocated; 844.94 MiB free; 20.54 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(start_epoch_num, start_epoch_num+epoch_num)):\n",
    "    epoch_loss = 0\n",
    "            \n",
    "    for i, batched_sample in tqdm(enumerate(dataloader)):\n",
    "        '''innerdomain backpropagate'''\n",
    "#         print(i)\n",
    "        input0 = batched_sample['img0'].double()#.to(device)\n",
    "        input1 = batched_sample['img1'].double()#.to(device)\n",
    "        input2 = batched_sample['img2'].double()#.to(device)\n",
    "        input3 = batched_sample['img3'].double()#.to(device)\n",
    "#         print(input.shape)\n",
    "        input0.requires_grad = True\n",
    "        input1.requires_grad = True\n",
    "        input2.requires_grad = True\n",
    "        input3.requires_grad = True\n",
    "        # u_pred: [batch_size, *data_shape, feature_num] = [1, 5, ...]\n",
    "        output_pred = net(input0,input1,input2,input3)\n",
    "        output_true = batched_sample['mask']#.to(device)#.double()\n",
    "#         print(output_pred.shape, output_true.shape)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "#         loss = criterion(output_pred, output_true.squeeze())\n",
    "        loss = criterion(output_pred, output_true.double())\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    with open(f'{output_dir}/loss.txt', 'a') as f:\n",
    "        f.write(f'{epoch_loss}\\n')\n",
    "    \n",
    "    print(f'epoch {epoch} innerdomain loss: {epoch_loss}')#, norm: {torch.norm(f_pred,2)**2}\n",
    "    epoch_loss_list.append(epoch_loss)\n",
    "    if epoch%1==0:       \n",
    "        if save_model:\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': epoch_loss,\n",
    "            }, f'{output_dir}/epoch_{epoch}_checkpoint.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_id.shape)\n",
    "print(output_pred_id.shape, output_true_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_true.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.title('Innerdomain loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.plot(epoch_loss_list)\n",
    "plt.savefig(f'{output_dir}/adadelta_loss_1e-1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch17",
   "language": "python",
   "name": "pytorch17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
