{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from dataset import *\n",
    "from model import *\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import math\n",
    "from itkwidgets import view \n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode='gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode=='gpu':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # after switch device, you need restart the kernel\n",
    "    torch.cuda.set_device(1)\n",
    "    torch.set_default_tensor_type('torch.cuda.DoubleTensor')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "### initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params 120237649, # conv layers 62\n"
     ]
    }
   ],
   "source": [
    "epoch = 35\n",
    "output_dir = '/home/sci/hdai/Projects/LnSeg/Models/UNet1024'\n",
    "checkpoint = torch.load(f'{output_dir}/epoch_{epoch}_checkpoint.pth.tar')\n",
    "model = UNet1024()\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "net = torch.nn.DataParallel(model, device_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/88 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fac633d60e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mslice_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mslice_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslice_name_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcmread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{ct_folder_path}/{slice_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mslice_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch17/lib/python3.7/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mdcmread\u001b[0;34m(fp, defer_size, stop_before_pixels, force, specific_tags)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         dataset = read_partial(fp, stop_when, defer_size=defer_size,\n\u001b[0;32m--> 888\u001b[0;31m                                force=force, specific_tags=specific_tags)\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcaller_owns_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch17/lib/python3.7/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(fileobj, stop_when, defer_size, force, specific_tags)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Read preamble (if present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m     \u001b[0mpreamble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_preamble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m     \u001b[0;31m# Read any File Meta Information group (0002,eeee) elements (if present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mfile_meta_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_file_meta_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch17/lib/python3.7/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_preamble\u001b[0;34m(fp, force)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \"\"\"\n\u001b[1;32m    606\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading File Meta Information preamble...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m     \u001b[0mpreamble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugging\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes2hex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreamble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"...\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbytes2hex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreamble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "case_info = []\n",
    "root_dir = '/home/sci/hdai/Projects/Dataset/LymphNodes'\n",
    "patch_size = 128\n",
    "field_list = ['Series UID', 'Collection', '3rd Party Analysis', \n",
    "                      'Data Description URI', 'Subject ID', 'Study UID', \n",
    "                      'Study Description', 'Study Date', 'Series Description', \n",
    "                      'Manufacturer', 'Modality', 'SOP Class Name', \n",
    "                      'SOP Class UID', 'Number of Images', 'File Size', \n",
    "                      'File Location', 'Download Timestamp']\n",
    "with open(f'{root_dir}/metadata.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        case_info.append({field_list[i]:row[i] for i in range(len(row))})\n",
    "\n",
    "case_info = case_info[87:]\n",
    "        \n",
    "for case in tqdm(case_info):         \n",
    "#         construct 3d CT from dicom folder\n",
    "        # '/CT Lymph Nodes/ABD_LYMPH_003/09-14-2014-ABDLYMPH003-abdominallymphnodes-39052/abdominallymphnodes-65663'\n",
    "    relative_ct_folder_path = case['File Location'][1:].replace('\\\\','/')\n",
    "        # '/home/sci/hdai/Projects/LymphNodes/CT Lymph Nodes/ABD_LYMPH_003/09-14-2014-ABDLYMPH003-abdominallymphnodes-39052/abdominallymphnodes-65663'\n",
    "    ct_folder_path = f'{root_dir}{relative_ct_folder_path}'\n",
    "    slice_name_list = [f for f in os.listdir(ct_folder_path)]\n",
    "    slice_name_list.sort()\n",
    "    slice_list = []\n",
    "    for slice_name in slice_name_list:\n",
    "        ds = pd.dcmread(f'{ct_folder_path}/{slice_name}')\n",
    "        slice_list.append(torch.from_numpy(ds.pixel_array.transpose()))\n",
    "    img = torch.stack(slice_list,-1).to(device)\n",
    "    \n",
    "    case_name = case['File Location'][17:30].replace('\\\\','/')\n",
    "    mask_path = f'{root_dir}/MED_ABD_LYMPH_MASKS/{case_name}/{case_name}_mask.nii.gz'\n",
    "    mask = torch.from_numpy(nib.load(mask_path).get_fdata()).to(device)\n",
    "    mask[mask>1] = 1\n",
    "    \n",
    "    half_patch_size = int(patch_size/2)\n",
    "    idx_x, idx_y, idx_z = torch.where(mask!=0)\n",
    "    centroid_x, centroid_y, centroid_z = 256, 256, 300\n",
    "    if int(torch.mean(idx_x.float())) < mask.shape[0]-half_patch_size and int(torch.mean(idx_x.float())) > half_patch_size:\n",
    "        centroid_x = int(torch.mean(idx_x.float()))\n",
    "    if int(torch.mean(idx_y.float())) < mask.shape[1]-half_patch_size and int(torch.mean(idx_y.float())) > half_patch_size:\n",
    "        centroid_y = int(torch.mean(idx_y.float()))\n",
    "    if int(torch.mean(idx_z.float())) < mask.shape[2]-half_patch_size and int(torch.mean(idx_z.float())) > half_patch_size:\n",
    "        centroid_z = int(torch.mean(idx_z.float()))\n",
    "    img = img[centroid_x-half_patch_size:centroid_x+half_patch_size, centroid_y-half_patch_size:centroid_y+half_patch_size, centroid_z-half_patch_size:centroid_z+half_patch_size]\n",
    "    mask_pred = model(img.unsqueeze(0).unsqueeze(0))\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    mask_pred = sigmoid(mask_pred).squeeze()\n",
    "    \n",
    "#     segment_depth = 128\n",
    "#     segment_num = math.ceil(img.shape[2]/segment_depth)\n",
    "#     mask_pred_segment_list = []\n",
    "#     for i in range(segment_num):\n",
    "#         begin = i*segment_depth\n",
    "#         end = min(i*segment_depth+segment_depth,img.shape[2])\n",
    "#         mask_pred_segment = model(img[192:320,192:320,begin:end].unsqueeze(0).unsqueeze(0))\n",
    "#         mask_pred_segment_list.append(mask_pred_segment)\n",
    "        \n",
    "#     mask_pred = torch.stack(mask_pred_segment_list,-1)\n",
    "    print(case_name)\n",
    "    mask_path = f'{output_dir}/PredResult/{case_name}_pred_mask.nii.gz'\n",
    "    nib.save(nib.Nifti1Image(mask_pred.cpu().detach().numpy(), None), mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_info = []\n",
    "root_dir = '/home/sci/hdai/Projects/Dataset/LymphNodes'\n",
    "patch_size = 128\n",
    "field_list = ['Series UID', 'Collection', '3rd Party Analysis', \n",
    "                      'Data Description URI', 'Subject ID', 'Study UID', \n",
    "                      'Study Description', 'Study Date', 'Series Description', \n",
    "                      'Manufacturer', 'Modality', 'SOP Class Name', \n",
    "                      'SOP Class UID', 'Number of Images', 'File Size', \n",
    "                      'File Location', 'Download Timestamp']\n",
    "with open(f'{root_dir}/metadata.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        case_info.append({field_list[i]:row[i] for i in range(len(row))})\n",
    "\n",
    "case_info = case_info[87:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50 #1\n",
    "\n",
    "relative_ct_folder_path = case_info[idx]['File Location'][1:].replace('\\\\','/')\n",
    "# '/home/sci/hdai/Projects/LymphNodes/CT Lymph Nodes/ABD_LYMPH_003/09-14-2014-ABDLYMPH003-abdominallymphnodes-39052/abdominallymphnodes-65663'\n",
    "ct_folder_path = f'{root_dir}{relative_ct_folder_path}'\n",
    "slice_name_list = [f for f in os.listdir(ct_folder_path)]\n",
    "slice_name_list.sort()\n",
    "slice_list = []\n",
    "for slice_name in slice_name_list:\n",
    "    ds = pd.dcmread(f'{ct_folder_path}/{slice_name}')\n",
    "    slice_list.append(torch.from_numpy(ds.pixel_array.transpose()))\n",
    "img = torch.stack(slice_list,-1)\n",
    "\n",
    "case_name = case_info[idx]['File Location'][17:30].replace('\\\\','/')\n",
    "mask_path = f'/home/sci/hdai/Projects/Dataset/LymphNodes/MED_ABD_LYMPH_MASKS/{case_name}/{case_name}_mask.nii.gz'\n",
    "mask = torch.from_numpy(nib.load(mask_path).get_fdata())\n",
    "mask[mask>1] = 1\n",
    "\n",
    "mask_pred_path = f'/home/sci/hdai/Projects/LnSeg/Models/UNet1024/PredResult/{case_name}_pred_mask.nii.gz'\n",
    "mask_pred = torch.from_numpy(nib.load(mask_pred_path).get_fdata())\n",
    "# mask_pred[mask_pred>=0.5] = 1\n",
    "# mask_pred[mask_pred<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_patch_size = int(patch_size/2)\n",
    "idx_x, idx_y, idx_z = torch.where(mask!=0)\n",
    "centroid_x, centroid_y, centroid_z = 256, 256, 300\n",
    "if int(torch.mean(idx_x.float())) < mask.shape[0]-half_patch_size and int(torch.mean(idx_x.float())) > half_patch_size:\n",
    "    centroid_x = int(torch.mean(idx_x.float()))\n",
    "if int(torch.mean(idx_y.float())) < mask.shape[1]-half_patch_size and int(torch.mean(idx_y.float())) > half_patch_size:\n",
    "    centroid_y = int(torch.mean(idx_y.float()))\n",
    "if int(torch.mean(idx_z.float())) < mask.shape[2]-half_patch_size and int(torch.mean(idx_z.float())) > half_patch_size:\n",
    "    centroid_z = int(torch.mean(idx_z.float()))\n",
    "img = img[centroid_x-half_patch_size:centroid_x+half_patch_size, centroid_y-half_patch_size:centroid_y+half_patch_size, centroid_z-half_patch_size:centroid_z+half_patch_size]\n",
    "mask = mask[centroid_x-half_patch_size:centroid_x+half_patch_size, centroid_y-half_patch_size:centroid_y+half_patch_size, centroid_z-half_patch_size:centroid_z+half_patch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f2cc2f5a1b4cfca871cdabf67091a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, point_sets=[], rendered_image=<itk.itkImagePython.itkImageSS3; pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f223f0379f47af9a8d0a8277721bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, point_sets=[], rendered_image=<itk.itkImagePython.itkImageD3; pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711d58bfc5454d22bdf986496de423b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, point_sets=[], rendered_image=<itk.itkImagePython.itkImageD3; pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(mask_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSC evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [17:53<00:00, 12.20s/it]\n"
     ]
    }
   ],
   "source": [
    "dice_score_list = []\n",
    "\n",
    "for idx in tqdm(range(len(case_info))):\n",
    "#     idx = 50 #1\n",
    "\n",
    "    relative_ct_folder_path = case_info[idx]['File Location'][1:].replace('\\\\','/')\n",
    "    # '/home/sci/hdai/Projects/LymphNodes/CT Lymph Nodes/ABD_LYMPH_003/09-14-2014-ABDLYMPH003-abdominallymphnodes-39052/abdominallymphnodes-65663'\n",
    "    ct_folder_path = f'{root_dir}{relative_ct_folder_path}'\n",
    "    slice_name_list = [f for f in os.listdir(ct_folder_path)]\n",
    "    slice_name_list.sort()\n",
    "    slice_list = []\n",
    "    for slice_name in slice_name_list:\n",
    "        ds = pd.dcmread(f'{ct_folder_path}/{slice_name}')\n",
    "        slice_list.append(torch.from_numpy(ds.pixel_array.transpose()))\n",
    "    img = torch.stack(slice_list,-1)\n",
    "\n",
    "    case_name = case_info[idx]['File Location'][17:30].replace('\\\\','/')\n",
    "    mask_path = f'/home/sci/hdai/Projects/Dataset/LymphNodes/MED_ABD_LYMPH_MASKS/{case_name}/{case_name}_mask.nii.gz'\n",
    "    mask = torch.from_numpy(nib.load(mask_path).get_fdata())\n",
    "    mask[mask>1] = 1\n",
    "    \n",
    "    half_patch_size = int(patch_size/2)\n",
    "    idx_x, idx_y, idx_z = torch.where(mask!=0)\n",
    "    centroid_x, centroid_y, centroid_z = 256, 256, 300\n",
    "    if int(torch.mean(idx_x.float())) < mask.shape[0]-half_patch_size and int(torch.mean(idx_x.float())) > half_patch_size:\n",
    "        centroid_x = int(torch.mean(idx_x.float()))\n",
    "    if int(torch.mean(idx_y.float())) < mask.shape[1]-half_patch_size and int(torch.mean(idx_y.float())) > half_patch_size:\n",
    "        centroid_y = int(torch.mean(idx_y.float()))\n",
    "    if int(torch.mean(idx_z.float())) < mask.shape[2]-half_patch_size and int(torch.mean(idx_z.float())) > half_patch_size:\n",
    "        centroid_z = int(torch.mean(idx_z.float()))\n",
    "#     img = img[centroid_x-half_patch_size:centroid_x+half_patch_size, centroid_y-half_patch_size:centroid_y+half_patch_size, centroid_z-half_patch_size:centroid_z+half_patch_size]\n",
    "    mask = mask[centroid_x-half_patch_size:centroid_x+half_patch_size, centroid_y-half_patch_size:centroid_y+half_patch_size, centroid_z-half_patch_size:centroid_z+half_patch_size]\n",
    "\n",
    "    mask_pred_path = f'/home/sci/hdai/Projects/LnSeg/Models/UNet1024/PredResult/{case_name}_pred_mask.nii.gz'\n",
    "    mask_pred = torch.from_numpy(nib.load(mask_pred_path).get_fdata())\n",
    "    \n",
    "    threshold = 0.05\n",
    "    mask_pred[mask_pred>=threshold]=1\n",
    "    mask_pred[mask_pred<threshold]=0\n",
    "    \n",
    "    dice_score = torch.sum(2*mask*mask_pred)/torch.sum(mask+mask_pred)\n",
    "    dice_score_list.append(dice_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.037837500334489925,\n",
       " 0.07237193678906786,\n",
       " 0.21423269126278977,\n",
       " 0.12874634536612703,\n",
       " 0.19702454373820014,\n",
       " 0.27397494062264444,\n",
       " 0.13945103833029213,\n",
       " 0.034085166980568696,\n",
       " 0.41503299516883674,\n",
       " 0.026016720742991536,\n",
       " 0.009768211299464698,\n",
       " 0.1736218720753617,\n",
       " 0.13160417350108,\n",
       " 0.18062853382305818,\n",
       " 0.10605138195543651,\n",
       " 0.058498294330489885,\n",
       " 0.06520400526709674,\n",
       " 0.05287595701641331,\n",
       " 0.3022813903674629,\n",
       " 0.03110995012285614,\n",
       " 0.11043663951929895,\n",
       " 0.14953188835677222,\n",
       " 0.06161135511603011,\n",
       " 0.2649540820269957,\n",
       " 0.3959286896250273,\n",
       " 0.0,\n",
       " 0.09487177248238345,\n",
       " 0.0054200706675133,\n",
       " 0.0036163749457543757,\n",
       " 0.031155581308720665,\n",
       " 0.10472545052626465,\n",
       " 0.04981060606060606,\n",
       " 0.003690313321794533,\n",
       " 0.16764394407840963,\n",
       " 0.12997151676931565,\n",
       " 0.16021520323706545,\n",
       " 0.03507762362860753,\n",
       " 0.09390544052598063,\n",
       " 0.06882976478138582,\n",
       " 0.2410515710836961,\n",
       " 0.03467887782294831,\n",
       " 0.0,\n",
       " 0.012413556118723423,\n",
       " 0.004694795750869643,\n",
       " 0.28851732715031375,\n",
       " 0.07543336259957802,\n",
       " 0.04929009700168883,\n",
       " 0.177412123006641,\n",
       " 0.009604035635175994,\n",
       " 0.2059568915765438,\n",
       " 0.105548412924484,\n",
       " 0.16877571737428998,\n",
       " 0.3155210265010107,\n",
       " 0.11998266220919504,\n",
       " 0.0,\n",
       " 0.46550146449449964,\n",
       " 0.42309997965098695,\n",
       " 0.17248221056458735,\n",
       " 0.0963856455675562,\n",
       " 0.1533656231829349,\n",
       " 0.0237541288611556,\n",
       " 0.007298797035116854,\n",
       " 0.029319276032384965,\n",
       " 0.23152783755823875,\n",
       " 0.1736573541171366,\n",
       " 0.015151684077910205,\n",
       " 0.0,\n",
       " 0.43020708961790355,\n",
       " 0.13601956445790148,\n",
       " 0.3443214060101899,\n",
       " 0.02899916805665411,\n",
       " 0.1790770139443664,\n",
       " 0.028005313739998875,\n",
       " 0.30811189261870797,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.03359820900350283,\n",
       " 0.029397957534573384,\n",
       " 0.09748193735276547,\n",
       " 0.06964317310527868,\n",
       " 0.11607537220632903,\n",
       " 0.0,\n",
       " 0.15617454342673917,\n",
       " 0.14226707499155378,\n",
       " 0.15297878523684974,\n",
       " 0.10325741338295216,\n",
       " 0.16385185305737174,\n",
       " 0.022071206568420283]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch17",
   "language": "python",
   "name": "pytorch17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
